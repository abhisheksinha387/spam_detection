Spam Detection Project
A machine learning-based web application built with Flask to classify text messages as spam or ham (non-spam). The project uses a Support Vector Machine (SVM) model trained on text embeddings generated by a SentenceTransformer model, with additional text features processed using SpaCy.
Table of Contents

Project Overview
Features
Project Structure
Prerequisites
Local Setup
Running the Application Locally
Deploying on Render
Dataset
Contributing
License

Project Overview
This project implements a spam detection system that:

Ingests a dataset of text messages labeled as spam or ham.
Processes the data by generating text embeddings and extracting features like character count, word count, and sentence count.
Trains an SVM model using the processed features.
Provides a Flask-based web interface to input text and predict whether it’s spam or ham.

The pipeline is modular, with components for data ingestion, transformation, model training, and prediction, all integrated into a Flask web app.
Features

Data Ingestion: Loads and preprocesses the dataset, splitting it into train and test sets.
Data Transformation: Generates text embeddings using SentenceTransformer (all-MiniLM-L6-v2) and extracts text features with SpaCy.
Model Training: Trains a Linear SVM model with GridSearchCV for hyperparameter tuning.
Web Interface: A user-friendly Flask app with a form to input text and display predictions.
Logging and Exception Handling: Custom logging and error handling for robust debugging.
Deployment Ready: Configured for easy deployment on Render.

Project Structure
spam_detection/
├── notebooks/
│   └── spam.csv              # Input dataset (optional, see Dataset section)
├── src/
│   ├── components/
│   │   ├── data_ingestion.py     # Data loading and splitting
│   │   ├── data_transformation.py # Feature extraction and embeddings
│   │   ├── model_trainer.py      # Model training and evaluation
│   ├── pipeline/
│   │   ├── predict_pipeline.py    # Prediction pipeline for web app
│   │   ├── train_pipeline.py     # Full training pipeline
│   ├── exception.py              # Custom exception handling
│   ├── logger.py                 # Custom logging setup
│   ├── utils.py                  # Utility functions for feature engineering
├── templates/
│   ├── index.html                # Flask app HTML template
├── app.py                        # Flask web application
├── requirements.txt              # Project dependencies
├── setup.py                      # Setup for package installation
├── .gitignore                    # Git ignore file
├── README.md                     # This file

Note: The logs/ and artifacts/ folders are generated at runtime and should not be included in the repository (see .gitignore).
Prerequisites

Python 3.8+
Git
A GitHub account for deployment
A Render account for hosting (optional)
The spam.csv dataset (see Dataset section)

Local Setup

Clone the Repository:
git clone https://github.com/<your-username>/spam-detection.git
cd spam-detection


Set Up a Virtual Environment:
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate


Install Dependencies:
pip install -r requirements.txt
python -m spacy download en_core_web_sm


Prepare the Dataset:

Place spam.csv in the notebooks/ folder.
Ensure it has columns v1 (labels: ham or spam) and v2 (text messages).
Alternatively, update src/components/data_ingestion.py to fetch the dataset from a URL (see Dataset).


Run the Training Pipeline:
python -m src.pipeline.train_pipeline

This generates the artifacts/ folder with:

model.pkl: Trained SVM model
preprocessor.pkl: SentenceTransformer model
train.csv, test.csv, data.csv: Processed datasets
train_embeddings.csv, test_embeddings.csv: Feature embeddings
train_target.csv, test_target.csv: Target labels



Running the Application Locally

Start the Flask App:
python app.py


Access the Web Interface:

Open http://localhost:5000 in a browser.
Enter a text message in the form and click “Predict” to see if it’s classified as spam or ham.


Logs:

Check the logs/ folder for runtime logs (e.g., errors or pipeline progress).



Deploying on Render
To host the Flask app on Render:

Push to GitHub:

Ensure logs/ and artifacts/ are excluded via .gitignore.
Optionally include artifacts/ for initial deployment or use a Render Disk (see below).
Push to your GitHub repository:git add .
git commit -m "Prepare for Render deployment"
git push origin main




Create a Web Service:

Log in to Render.
Click “New” > “Web Service” and connect your GitHub repository.
Configure:
Name: e.g., spam-detection-app
Runtime: Python
Branch: main
Build Command: pip install -r requirements.txt && python -m spacy download en_core_web_sm
Start Command: python app.py
Instance Type: Free (or upgrade for Disk persistence)




Handle Artifacts and Dataset:

Option 1: Commit Artifacts:
Temporarily remove artifacts/ from .gitignore and commit model.pkl, preprocessor.pkl, etc.
Push to GitHub and deploy.


Option 2: Use Render Disk (requires paid plan):
Add a Disk in Render Dashboard:
Name: artifacts-disk
Mount Path: /app/artifacts
Size: 1GB


Update file paths in data_ingestion.py and data_transformation.py:# In src/components/data_ingestion.py
train_data_path: str = os.path.join('/app/artifacts', 'train.csv')
test_data_path: str = os.path.join('/app/artifacts', 'test.csv')
raw_data_path: str = os.path.join('/app/artifacts', 'data.csv')
input_data_path: str = os.path.join('/app/artifacts', 'spam.csv')

# In src/components/data_transformation.py
preprocessor_obj_file_path: str = os.path.join('/app/artifacts', 'preprocessor.pkl')
train_embeddings_path: str = os.path.join('/app/artifacts', 'train_embeddings.csv')
test_embeddings_path: str = os.path.join('/app/artifacts', 'test_embeddings.csv')
train_target_path: str = os.path.join('/app/artifacts', 'train_target.csv')
test_target_path: str = os.path.join('/app/artifacts', 'test_target.csv')


Copy spam.csv to the disk:# Update Build Command
pip install -r requirements.txt && python -m spacy download en_core_web_sm && cp notebooks/spam.csv /app/artifacts/spam.csv


Run the pipeline on startup:# Update Start Command
python -m src.pipeline.train_pipeline && python app.py




Option 3: External Dataset:
Host spam.csv on a public URL (e.g., Google Drive).
Update data_ingestion.py to download it:import requests
def initiate_data_ingestion(self):
    logging.info("Entered the data ingestion method or components.")
    try:
        url = "https://your-public-url/spam.csv"
        logging.info(f"Downloading dataset from {url}")
        response = requests.get(url)
        with open('temp_spam.csv', 'wb') as f:
            f.write(response.content)
        df = pd.read_csv('temp_spam.csv', encoding='latin-1')
        # Rest of the code






Deploy and Test:

Click “Create Web Service” to deploy.
Access the app at the provided Render URL (e.g., spam-detection-app.onrender.com).
Test the prediction form.
Check Render logs for errors.


Notes:

The Free tier has an ephemeral filesystem, so artifacts are lost on redeploy unless committed or stored on a Disk.
Free tier may suspend for excessive traffic; consider a paid plan for production.



Dataset
The project uses spam.csv, which should have:

Columns: v1 (labels: ham or spam), v2 (text messages).
Location: notebooks/spam.csv or a public URL.
Obtaining: If not included in the repo, download from Kaggle SMS Spam Collection Dataset or another source and place in notebooks/.

To use a URL-based dataset:

Update input_data_path in src/components/data_ingestion.py.
Modify initiate_data_ingestion to download the file (see Deploying on Render > Option 3).

Contributing

Fork the repository.
Create a feature branch: git checkout -b feature-name.
Commit changes: git commit -m "Add feature".
Push to the branch: git push origin feature-name.
Open a Pull Request.

Please follow the [Contributor Covenant Code of Conduct](https atherosclerosis://www.contributor-covenant.org/version/2/0/code_of_conduct/).
License
This project is licensed under the MIT License. See the LICENSE file for details.

Author: AbhishekEmail: abhisheksinha.7742@gmail.comDate: June 2025